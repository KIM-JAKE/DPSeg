# Hypersim semseg config

# Finetune from:
finetune: '/path/to/pretrained_weights' # Change me

# Input tasks
in_domains: depth
decoder_main_tasks: depth
use_mask_valid: True # Requires "task" mask_valid to be saved to disk


# Architecture
model: multivit_base
patch_size: 16
num_global_tokens: 1
drop_path_encoder: 0.1
output_adapter: convnext
decoder_dim: 6144
decoder_preds_per_patch: 16
decoder_depth: 4

# Train
epochs: 25
opt: adamw
lr: 0.0001 # = 1e-4
warmup_lr: 0.000001 # = 1e-6
min_lr: 0.
warmup_epochs: 1
batch_size: 4
input_size: 512
layer_decay: 0.75

# Augmentation
aug_name: simple

# Data info
data_path: '/path/to/dataset' # Change me
eval_data_path: '/path/to/eval_dataset' # Change me
test_data_path: null # Change me
num_classes: 40
dataset_name: hypersim
dist_eval: True
seg_reduce_zero_label: True
eval_freq: 1

# Misc.
find_unused_params: False
fp16: False

# Wandb and logging
log_wandb: False # Set to True to activate logging to Weights & Biases
wandb_project: 'multimae-finetune-semseg'
wandb_entity: null # Change if needed
wandb_run_name: ft_hypersim_25e_multimae-b_depth
log_images_wandb: True
log_images_freq: 5
output_dir: 'output/finetune/semseg/hypersim/ft_hypersim_25e_multimae-b_depth'
