# NYU semseg config

# Finetune from:
finetune:  "/root/datasets/multimae-b_98_rgb+-depth-semseg_1600e_multivit-afff3f8c (1).pth"

# Input tasks
in_domains: rgb

# Architecture
model: multivit_base
patch_size: 16
num_global_tokens: 0
drop_path_encoder: 0.1
output_adapter: convnext
decoder_dim: 6144
decoder_preds_per_patch: 16
decoder_depth: 4

# Train
epochs: 1000
opt: adamw
lr: 0.0001 # = 1e-4
warmup_lr: 0.000001 # = 1e-6
min_lr: 0.000001
warmup_epochs: 1
batch_size: 24
input_size: 336
layer_decay: 0.2
weight_decay: 0.4
# Augmentation
aug_name: simple

# Data info
data_path: "/root/datasets/NYUv2_Dataset/NYUv2/NYUv2/train"
eval_data_path: "/root/datasets/NYUv2_Dataset/NYUv2/NYUv2/test" # Change me
num_classes: 40
dataset_name: nyu
dist_eval: True
seg_reduce_zero_label: True
eval_freq: 10

# Misc.
find_unused_params: False

#prompt
prompt_mode : deep
prompt_pool : True
prompt_shallow : False
prompt_deep : True
top_k : 7
size : 15
length : 5
task_specific_prompt_length : 20
not_self_attn : False
use_prompt_mask : True

# Wandb and l0ogging
log_wandb: True # Set to True to log to Weights & Biases
wandb_project:  'multimae-multi-l2p-deep-TTTT'
wandb_entity: null # Change if needed
wandb_run_name: 'Test_Masking_task_weight_init=10:1'
log_images_wandb: False
log_images_freq: 20
output_dir: '/root/workspace/Results/-pool_defalut_task_specific_prompt_from_encoder_Dual_Prompt_Method'